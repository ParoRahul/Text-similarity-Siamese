{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "from myModel import Mymodel\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=5000 , \n",
    "max_sequence_length=25,\n",
    "embedding_dim = 256,\n",
    "number_lstm_units = 256,\n",
    "number_dense_units = 256,\n",
    "rate_drop_lstm = 0.17 , \n",
    "rate_drop_dense = 0.01\n",
    "df =pd.read_csv('./dataset/dictonary.csv')\n",
    "imgDir='D:\\TF\\image-Text-similarity\\dataset\\Triplet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517 517\n",
      "413 104\n",
      "413 104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dictonary = []\n",
    "labels = []\n",
    "imagePath = []\n",
    "dataset = []\n",
    "for index,row in df.iterrows():\n",
    "    labels.append(int(row['id']))\n",
    "    dictonary.append(row['text'])\n",
    "#imagePath = [ os.path.join(imgDir,str(name)+'.jpeg') for name in labels ]\n",
    "dataset = []\n",
    "train_dictonary, train_labels = shuffle(dictonary,\n",
    "                                          labels,\n",
    "                                          random_state=1)\n",
    "for name in train_labels:\n",
    "    imgPath = os.path.join(imgDir,str(name)+'.jpeg')\n",
    "    if os.path.exists(imgPath):\n",
    "        imagePath.append(imgPath) \n",
    "\n",
    "imagePath_train, imagePath_val, dictonary_train, dictonary_val = train_test_split(imagePath,dictonary,\n",
    "                                                                                  test_size=0.2,random_state=0)\n",
    "print(len(imagePath),len(dictonary)) \n",
    "print(len(imagePath_train),len(imagePath_val)) \n",
    "print(len(dictonary_train),len(dictonary_val)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size,\n",
    "                                                                oov_token=\"<unk>\",\n",
    "                                                                filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(dictonary)\n",
    "tokenizer.word_index['<pad>'] = 0                                                                 \n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "images = []\n",
    "for image_path in imagePath_train[10:]:\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    images.append(img)\n",
    "images =np.array(images)\n",
    "print(images.shape)\n",
    "#imges = tf.keras.applications.inception_v3.preprocess_input(tf.expand_dims(imges, 0))\n",
    "#freature_extratcor= tf.keras.applications.InceptionV3(include_top=False,weights='imagenet')\n",
    "#img_features=freature_extratcor(imges)\n",
    "#img_features = tf.reshape(img_features, (img_features.shape[0], img_features.shape[1]*img_features.shape[2]*img_features.shape[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 131072)\n"
     ]
    }
   ],
   "source": [
    "print(img_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03 QUARTER SLEEVE 1PULL ON 2KNEE LENGTH 3REGULAR FIT 4PLAIN 2KNEE LENGTH 6ROUND NECK 7UNLINED 8POLYESTER 9BLACK 5TUNICS 4.94\n",
      "(1, 25)\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "text_seqs = tokenizer.texts_to_sequences([text])\n",
    "#print(text_seqs)\n",
    "text_vector=tf.keras.preprocessing.sequence.pad_sequences(text_seqs, padding='post',maxlen=25)\n",
    "print(text_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_1_input = tf.keras.layers.Input(shape=(25,), dtype='int32')\n",
    "feature_2_input = tf.keras.layers.Input(shape=(8*8*2048,))\n",
    "embedding = tf.keras.layers.Embedding(500, 256)\n",
    "lstm_layer = tf.keras.layers.Bidirectional( tf.keras.layers.LSTM(\n",
    "                            256, dropout=0.17, \n",
    "                            recurrent_dropout=0.01))\n",
    "\n",
    "fully_connected_in=tf.keras.layers.Dense(256)\n",
    "fully_connected_out = tf.nn.relu(fully_connected_in(feature_2_input))\n",
    "lstm_input2=embedding(fully_connected_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
