{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from myModel import Mymodel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as td\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvdata = './dataset/dictonary.csv'\n",
    "imgDir = './dataset/imges'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictonary = []\n",
    "labels = []\n",
    "imagePath = []\n",
    "is_similar = []\n",
    "\n",
    "df =pd.read_csv(csvdata)\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    labels.append(int(row['id']))\n",
    "    dictonary.append(row['text'])\n",
    "    is_similar.append(row['is_similar'])\n",
    "\n",
    "dictonary, labels ,is_similar = shuffle(dictonary,\n",
    "                                          labels,\n",
    "                                          is_similar,\n",
    "                                          random_state=1)\n",
    "for name in labels:\n",
    "    imgPath = os.path.join(imgDir,str(name)+'.jpeg')\n",
    "    if os.path.exists(imgPath):\n",
    "        imagePath.append(imgPath) \n",
    "print(len(is_similar),len(dictonary),len(imagePath))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mymodel()\n",
    "model.prepare_tokenizer(dictonary) \n",
    "mod = model.model() \n",
    "mod.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath_train, imagePath_val, dictonary_train, dictonary_val,is_similar_train, is_similar_val = \\\n",
    "train_test_split(imagePath,dictonary,is_similar,test_size=0.2,random_state=0)\n",
    "img_features_train, text_vector_train =model.dataPost_processing(imagePath_train,dictonary_train)\n",
    "gc.collect()\n",
    "img_features_val, text_vector_val =model.dataPost_processing(imagePath_val,dictonary_val)\n",
    "gc.collect()\n",
    "is_similar_train = np.array(is_similar_train) \n",
    "is_similar_val = np.array(is_similar_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_features_train.shape,text_vector_train.shape,is_similar_train.shape)\n",
    "print(img_features_val.shape,text_vector_val.shape,is_similar_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
    "STAMP = 'lstm_%d_%d_%.2f_%.2f' % (model.number_lstm_units, model.number_dense_units, model.rate_drop_lstm, model.rate_drop_dense)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpoint_dir = model.model_save_directory + 'checkpoints/' + str(int(time.time())) + '/'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)  \n",
    "bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))\n",
    "\n",
    "mod.fit([text_vector_train,img_features_train], is_similar_train,\n",
    "          validation_data=([text_vector_val,img_features_val], is_similar_val),\n",
    "          epochs=20, batch_size=16, shuffle=True,\n",
    "          callbacks=[early_stopping, model_checkpoint, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}